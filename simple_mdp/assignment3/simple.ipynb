{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, size, start_cell, obstacles, terminating_state):\n",
    "        self.size = size\n",
    "        self.start = start_cell\n",
    "        self.obstacles = obstacles\n",
    "        self.termin = terminating_state\n",
    "        self.current_cell = self.start\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_cell = self.start\n",
    "    \n",
    "    def transition(self, cell, action):\n",
    "\n",
    "        r_current = cell[0]\n",
    "        c_current = cell[1]\n",
    "        \n",
    "        if action == 0:\n",
    "          cell = (r_current,c_current-1)\n",
    "        if action == 1:\n",
    "          cell = (r_current-1,c_current)\n",
    "        if action == 2:\n",
    "          cell = (r_current,c_current+1)\n",
    "        if action == 3:\n",
    "          cell = (r_current+1,c_current)\n",
    "\n",
    "        if (cell[0], cell[1]) in self.obstacles:\n",
    "          cell = (r_current,c_current)\n",
    "\n",
    "        if cell[0] < 0 \\\n",
    "             or cell[0] > self.size[0] -1 \\\n",
    "             or cell[1] < 0  \\\n",
    "             or cell[1] > self.size[1] -1 : \n",
    "          cell = (r_current, c_current)\n",
    "        \n",
    "        self.current_cell = cell\n",
    "        \n",
    "        return cell\n",
    "\n",
    "    def reward(self, cell, action):\n",
    "        cell_state = cell\n",
    "        if self.transition(cell, action) != self.termin:\n",
    "          reward = -1\n",
    "        else:\n",
    "          reward = 0\n",
    "        self.current_cell = cell_state\n",
    "        return reward\n",
    "\n",
    "    def in_terminal(self):\n",
    "        return self.current_cell == self.termin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, gridworld, gamma, alpha, episodes):\n",
    "        self.gridworld = gridworld\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.episodes = episodes\n",
    "        size = gridworld.size\n",
    "        self.q_table =  self.q_table = np.zeros((4,) + size)   \n",
    "        self.eps = 0.9\n",
    "        self.episode = 0\n",
    "        self.sum_rewards = []\n",
    "        self.path = []\n",
    "    \n",
    "    def update(self, cell, action, reward, next_cell):\n",
    "        r_t, c_t = cell  # current state\n",
    "        r_tp1, c_tp1 = next_cell  # next state\n",
    "        q_current_step = self.q_table[action, r_t, c_t] \n",
    "        q_next_step = max(self.q_table[:, r_tp1, c_tp1])      \n",
    "        error_term = reward + self.gamma * q_next_step - q_current_step\n",
    "        self.q_table[action, r_t, c_t] = q_current_step + self.alpha * (error_term)\n",
    "    \n",
    "    def choose_action(self, cell):\n",
    "        r, c = cell\n",
    "        if np.random.random() > (1 - self.eps):\n",
    "            action = np.argmax(self.q_table[:, r, c])\n",
    "        else:\n",
    "            action = np.random.randint(low=0, high=4)\n",
    "        return action\n",
    "    \n",
    "    def anneal_epsilon(self):\n",
    "        self.eps = max(0, self.eps * (1 - self.episode / self.episodes * 1.5))\n",
    "    \n",
    "    def one_episode(self):  \n",
    "        cntr = 0   \n",
    "        self.gridworld.reset()\n",
    "        self.sum_rewards.append(0)\n",
    "        while not self.gridworld.in_terminal() and cntr < 5000:\n",
    "            cntr += 1\n",
    "            cell = self.gridworld.current_cell\n",
    "            action = self.choose_action(cell)\n",
    "            reward = self.gridworld.reward(cell, action)\n",
    "            next_cell = self.gridworld.transition(cell, action)\n",
    "            self.update(cell, action, reward, next_cell)\n",
    "            self.sum_rewards[-1] += reward\n",
    "\n",
    "        print(\"Total Epi: {0: 5} Episode Steps: {1: 5} Reward: {2: 5.4f} \".format(\n",
    "                    self.episode, cntr, self.sum_rewards[-1]))\n",
    "        self.episode += 1\n",
    "        self.anneal_epsilon\n",
    "\n",
    "    def trajectory(self):\n",
    "        self.gridworld.reset()\n",
    "        self.path = []\n",
    "        sum_rewards = 0\n",
    "        itr = 0\n",
    "        while not self.gridworld.in_terminal() and itr < 20:\n",
    "            r, c = self.gridworld.current_cell\n",
    "            action = np.argmax(self.q_table[:, r, c])\n",
    "            sum_rewards += self.gridworld.reward((r, c), action)\n",
    "            self.gridworld.transition((r, c), action)\n",
    "            itr += 1\n",
    "            self.path.append((r, c))\n",
    "        return sum_rewards\n",
    "\n",
    "    def is_learning_finished(self):  \n",
    "        return self.episode > self.episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sarsa:\n",
    "    \n",
    "    def __init__(self, gridworld, gamma, alpha, episodes):\n",
    "        self.gridworld = gridworld\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.episodes = episodes\n",
    "        size = gridworld.size\n",
    "        self.q_table =  self.q_table = np.zeros((4,) + size) \n",
    "        self.eps = 0.9\n",
    "        self.episode = 0\n",
    "        self.sum_rewards = []\n",
    "        self.path = []\n",
    "    \n",
    "    def update(self, cell, action, reward, next_cell, next_action):\n",
    "        r_t, c_t = cell\n",
    "        r_tp1, c_tp1 = next_cell  \n",
    "        q_current_step = self.q_table[action, r_t, c_t] \n",
    "        q_next_step = self.q_table[next_action, r_tp1, c_tp1]\n",
    "        error_term = reward + self.gamma * q_next_step - q_current_step    # TD Error\n",
    "        self.q_table[action, r_t, c_t] = q_current_step + self.alpha * (error_term)\n",
    "    \n",
    "    def choose_action(self, cell):\n",
    "        r, c = cell\n",
    "        if np.random.random() > (1 - self.eps):\n",
    "            action = np.argmax(self.q_table[:, r, c])\n",
    "        else:\n",
    "            action = np.random.randint(low=0, high=4)\n",
    "        return action\n",
    "    \n",
    "    def anneal_epsilon(self):\n",
    "        self.eps = max(0, self.eps * (1 - self.episode / self.episodes * 1.5))\n",
    "    \n",
    "    def one_episode(self):  \n",
    "        first_step = True\n",
    "        cntr = 0\n",
    "        self.gridworld.reset()\n",
    "        self.sum_rewards.append(0)\n",
    "\n",
    "        while not self.gridworld.in_terminal() and cntr < 5000:\n",
    "            cntr += 1\n",
    "            cell = self.gridworld.current_cell\n",
    "            \n",
    "            if first_step == True:\n",
    "                action = self.choose_action(cell)\n",
    "                first_step = False\n",
    "            else:\n",
    "                action = next_action\n",
    "\n",
    "            reward = self.gridworld.reward(cell, action)\n",
    "            next_cell = self.gridworld.transition(cell, action) \n",
    "            next_action = self.choose_action(next_cell)\n",
    "            self.update(cell, action, reward, next_cell, next_action)\n",
    "            self.sum_rewards[-1] += reward\n",
    "\n",
    "        print(\"Total Epi: {0: 5} Episode Steps: {1: 5} Reward: {2: 5.4f} \".format(\n",
    "                    self.episode, cntr, self.sum_rewards[-1]))\n",
    "\n",
    "        self.episode += 1\n",
    "        self.anneal_epsilon\n",
    "    \n",
    "    def trajectory(self):\n",
    "        self.gridworld.reset()\n",
    "        self.path = []\n",
    "        sum_rewards = 0\n",
    "        itr = 0\n",
    "        while not self.gridworld.in_terminal() and itr < 20:\n",
    "            r, c = self.gridworld.current_cell\n",
    "            action = np.argmax(self.q_table[:, r, c])\n",
    "            sum_rewards += self.gridworld.reward((r, c), action)\n",
    "            self.gridworld.transition((r, c), action)\n",
    "            itr += 1\n",
    "            self.path.append((r, c))\n",
    "        return sum_rewards\n",
    "\n",
    "    def is_learning_finished(self):\n",
    "        return self.episode > self.episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(ql):\n",
    "    values = ql.sum_rewards\n",
    "    x = list(range(len(values)))\n",
    "    y = values\n",
    "    plt.plot(x, y, 'ro')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epi:     0 Episode Steps:   134 Reward: -133.0000 \n",
      "Total Epi:     1 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:     2 Episode Steps:    52 Reward: -51.0000 \n",
      "Total Epi:     3 Episode Steps:    38 Reward: -37.0000 \n",
      "Total Epi:     4 Episode Steps:    78 Reward: -77.0000 \n",
      "Total Epi:     5 Episode Steps:    67 Reward: -66.0000 \n",
      "Total Epi:     6 Episode Steps:    49 Reward: -48.0000 \n",
      "Total Epi:     7 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:     8 Episode Steps:    22 Reward: -21.0000 \n",
      "Total Epi:     9 Episode Steps:    90 Reward: -89.0000 \n",
      "Total Epi:    10 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:    11 Episode Steps:    53 Reward: -52.0000 \n",
      "Total Epi:    12 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    13 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    14 Episode Steps:    37 Reward: -36.0000 \n",
      "Total Epi:    15 Episode Steps:    59 Reward: -58.0000 \n",
      "Total Epi:    16 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    17 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    18 Episode Steps:    40 Reward: -39.0000 \n",
      "Total Epi:    19 Episode Steps:    72 Reward: -71.0000 \n",
      "Total Epi:    20 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    21 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    22 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    23 Episode Steps:    38 Reward: -37.0000 \n",
      "Total Epi:    24 Episode Steps:    29 Reward: -28.0000 \n",
      "Total Epi:    25 Episode Steps:    35 Reward: -34.0000 \n",
      "Total Epi:    26 Episode Steps:    31 Reward: -30.0000 \n",
      "Total Epi:    27 Episode Steps:    28 Reward: -27.0000 \n",
      "Total Epi:    28 Episode Steps:    50 Reward: -49.0000 \n",
      "Total Epi:    29 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    30 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    31 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:    32 Episode Steps:    30 Reward: -29.0000 \n",
      "Total Epi:    33 Episode Steps:    25 Reward: -24.0000 \n",
      "Total Epi:    34 Episode Steps:    32 Reward: -31.0000 \n",
      "Total Epi:    35 Episode Steps:    39 Reward: -38.0000 \n",
      "Total Epi:    36 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:    37 Episode Steps:    30 Reward: -29.0000 \n",
      "Total Epi:    38 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:    39 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    40 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    41 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    42 Episode Steps:    30 Reward: -29.0000 \n",
      "Total Epi:    43 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    44 Episode Steps:    35 Reward: -34.0000 \n",
      "Total Epi:    45 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    46 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    47 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    48 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:    49 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    50 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    51 Episode Steps:    22 Reward: -21.0000 \n",
      "Total Epi:    52 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:    53 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    54 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    55 Episode Steps:    33 Reward: -32.0000 \n",
      "Total Epi:    56 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    57 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    58 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    59 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    60 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    61 Episode Steps:    30 Reward: -29.0000 \n",
      "Total Epi:    62 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    63 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    64 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    65 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    66 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:    67 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    68 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    69 Episode Steps:    22 Reward: -21.0000 \n",
      "Total Epi:    70 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    71 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    72 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    73 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:    74 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    75 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    76 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:    77 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    78 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    79 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    80 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    81 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:    82 Episode Steps:    28 Reward: -27.0000 \n",
      "Total Epi:    83 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    84 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:    85 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    86 Episode Steps:    31 Reward: -30.0000 \n",
      "Total Epi:    87 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    88 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    89 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    90 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    91 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    92 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    93 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:    94 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    95 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    96 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    97 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:    98 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    99 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   100 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   101 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   102 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   103 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   104 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   105 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   106 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   107 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   108 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:   109 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   110 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   111 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   112 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   113 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   114 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   115 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   116 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   117 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:   118 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   119 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   120 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   121 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   122 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   123 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   124 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:   125 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   126 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   127 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   128 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   129 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   130 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   131 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   132 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   133 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   134 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   135 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   136 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   137 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   138 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   139 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   140 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   141 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   142 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   143 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   144 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   145 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   146 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:   147 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   148 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   149 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   150 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   151 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   152 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   153 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:   154 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   155 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:   156 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   157 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   158 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   159 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   160 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:   161 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   162 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   163 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:   164 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   165 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   166 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   167 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   168 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   169 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   170 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   171 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   172 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   173 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   174 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   175 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   176 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   177 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   178 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   179 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   180 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   181 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   182 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   183 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   184 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   185 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   186 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   187 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   188 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   189 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   190 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   191 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   192 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   193 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   194 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   195 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   196 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   197 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   198 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   199 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   200 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   201 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   202 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   203 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   204 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   205 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   206 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   207 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   208 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:   209 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   210 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   211 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   212 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   213 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   214 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   215 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   216 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   217 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   218 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   219 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   220 Episode Steps:    13 Reward: -12.0000 \n"
     ]
    }
   ],
   "source": [
    "size = (5, 5)\n",
    "start_cell = (0, 0)\n",
    "obstacles = [(2, 1), (1,3)]\n",
    "terminating_state = (4, 4)\n",
    "gamma = 0.9\n",
    "alpha = 0.1\n",
    "episodes = 220\n",
    "\n",
    "gw = GridWorld(size, start_cell, obstacles, terminating_state)\n",
    "solver = QLearning(gw, gamma, alpha, episodes)  \n",
    "\n",
    "while not solver.is_learning_finished():\n",
    "    solver.one_episode()\n",
    "    sum_rewards = solver.sum_rewards[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_rewards = solver.trajectory()\n",
    "print(sum_rewards)\n",
    "plot_learning_curve(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: 1 [-4.77850136 -4.75835169 -4.7373933  -4.734882  ] down\n",
      "state: 2 [-4.30894436 -4.28363035 -4.24108257 -4.2580982 ] right\n",
      "state: 3 [-3.79070615 -3.76474605 -3.72217546 -3.73898276] right\n",
      "state: 4 [-3.234809   -3.22666347 -3.23901968 -3.23378141] up\n",
      "state: 5 [-2.73720184 -2.67009577 -2.65808478 -2.62873566] down\n",
      "state: 6 [-4.29429706 -4.34286512 -4.24585895 -4.23998546] down\n",
      "state: 7 [-3.90380132 -3.88663988 -3.84492377 -3.87785615] right\n",
      "state: 8 [-3.25942141 -3.30702709 -3.29754619 -3.26106735] left\n",
      "state: 9 [0. 0. 0. 0.] left\n",
      "state: 10 [-1.89268163 -2.10362789 -1.97750082 -1.87930347] down\n",
      "state: 11 [-3.75075556 -3.75967665 -3.74140027 -3.71180818] down\n",
      "state: 12 [0. 0. 0. 0.] left\n",
      "state: 13 [-2.71851869 -2.7343497  -2.57136785 -2.56689073] down\n",
      "state: 14 [-1.83656164 -1.81670534 -1.81975805 -1.82345164] up\n",
      "state: 15 [-1.33769886 -1.33347869 -1.03896314 -0.9995889 ] down\n",
      "state: 16 [-3.16345602 -3.14414363 -3.11365382 -3.12212834] right\n",
      "state: 17 [-2.52530448 -2.57271839 -2.49255148 -2.49274926] right\n",
      "state: 18 [-1.87433777 -1.98924352 -1.84429302 -1.84610382] right\n",
      "state: 19 [-1.43093652 -1.22922418 -0.98669721 -0.98669721] right\n",
      "state: 20 [-0.5467185 -0.9251413 -0.19       0.       ] down\n",
      "state: 21 [-2.58322986 -2.60310242 -2.58872058 -2.59602423] left\n",
      "state: 22 [-1.98729422 -1.90765703 -1.88927586 -1.98145237] right\n",
      "state: 23 [-1.15382652 -1.09956926 -0.9998955  -1.13075846] right\n",
      "state: 24 [-0.9803187  -0.43766005  0.         -0.271     ] right\n",
      "state: 25 [0. 0. 0. 0.] left\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "name_action = [\"left\", \"up\", \"right\", \"down\"]\n",
    "for i in range (5):\n",
    "    for k in range (5):\n",
    "        action = name_action[np.argmax(solver.q_table[:,i,k])]\n",
    "        print(\"state:\", count, solver.q_table[:,i,k], action)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epi:     0 Episode Steps:   173 Reward: -172.0000 \n",
      "Total Epi:     1 Episode Steps:    56 Reward: -55.0000 \n",
      "Total Epi:     2 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:     3 Episode Steps:    48 Reward: -47.0000 \n",
      "Total Epi:     4 Episode Steps:    80 Reward: -79.0000 \n",
      "Total Epi:     5 Episode Steps:    28 Reward: -27.0000 \n",
      "Total Epi:     6 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:     7 Episode Steps:    86 Reward: -85.0000 \n",
      "Total Epi:     8 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:     9 Episode Steps:    39 Reward: -38.0000 \n",
      "Total Epi:    10 Episode Steps:    82 Reward: -81.0000 \n",
      "Total Epi:    11 Episode Steps:    29 Reward: -28.0000 \n",
      "Total Epi:    12 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    13 Episode Steps:    36 Reward: -35.0000 \n",
      "Total Epi:    14 Episode Steps:    25 Reward: -24.0000 \n",
      "Total Epi:    15 Episode Steps:    55 Reward: -54.0000 \n",
      "Total Epi:    16 Episode Steps:    37 Reward: -36.0000 \n",
      "Total Epi:    17 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    18 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    19 Episode Steps:    48 Reward: -47.0000 \n",
      "Total Epi:    20 Episode Steps:    38 Reward: -37.0000 \n",
      "Total Epi:    21 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    22 Episode Steps:    45 Reward: -44.0000 \n",
      "Total Epi:    23 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    24 Episode Steps:    30 Reward: -29.0000 \n",
      "Total Epi:    25 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:    26 Episode Steps:    51 Reward: -50.0000 \n",
      "Total Epi:    27 Episode Steps:    40 Reward: -39.0000 \n",
      "Total Epi:    28 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    29 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    30 Episode Steps:    32 Reward: -31.0000 \n",
      "Total Epi:    31 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    32 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    33 Episode Steps:    40 Reward: -39.0000 \n",
      "Total Epi:    34 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    35 Episode Steps:    59 Reward: -58.0000 \n",
      "Total Epi:    36 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:    37 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    38 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:    39 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    40 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    41 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    42 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    43 Episode Steps:    26 Reward: -25.0000 \n",
      "Total Epi:    44 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    45 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    46 Episode Steps:    28 Reward: -27.0000 \n",
      "Total Epi:    47 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:    48 Episode Steps:    28 Reward: -27.0000 \n",
      "Total Epi:    49 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    50 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    51 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    52 Episode Steps:    22 Reward: -21.0000 \n",
      "Total Epi:    53 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:    54 Episode Steps:    61 Reward: -60.0000 \n",
      "Total Epi:    55 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    56 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    57 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    58 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    59 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    60 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    61 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:    62 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:    63 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    64 Episode Steps:    35 Reward: -34.0000 \n",
      "Total Epi:    65 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:    66 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:    67 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:    68 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:    69 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    70 Episode Steps:    33 Reward: -32.0000 \n",
      "Total Epi:    71 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    72 Episode Steps:    27 Reward: -26.0000 \n",
      "Total Epi:    73 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:    74 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    75 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    76 Episode Steps:    22 Reward: -21.0000 \n",
      "Total Epi:    77 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    78 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    79 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    80 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:    81 Episode Steps:    22 Reward: -21.0000 \n",
      "Total Epi:    82 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:    83 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:    84 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    85 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    86 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:    87 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    88 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    89 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    90 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    91 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:    92 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    93 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:    94 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:    95 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:    96 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:    97 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:    98 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:    99 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:   100 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   101 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   102 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   103 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   104 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   105 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   106 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   107 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   108 Episode Steps:    24 Reward: -23.0000 \n",
      "Total Epi:   109 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   110 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   111 Episode Steps:    21 Reward: -20.0000 \n",
      "Total Epi:   112 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   113 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   114 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   115 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   116 Episode Steps:    15 Reward: -14.0000 \n",
      "Total Epi:   117 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   118 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   119 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   120 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   121 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:   122 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   123 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   124 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   125 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   126 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   127 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   128 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   129 Episode Steps:    23 Reward: -22.0000 \n",
      "Total Epi:   130 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   131 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   132 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   133 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   134 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   135 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   136 Episode Steps:    19 Reward: -18.0000 \n",
      "Total Epi:   137 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   138 Episode Steps:    25 Reward: -24.0000 \n",
      "Total Epi:   139 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   140 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   141 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:   142 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   143 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   144 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   145 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   146 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   147 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   148 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   149 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   150 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   151 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   152 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:   153 Episode Steps:    17 Reward: -16.0000 \n",
      "Total Epi:   154 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   155 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   156 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   157 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   158 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   159 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   160 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   161 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   162 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   163 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   164 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   165 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   166 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   167 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   168 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   169 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   170 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   171 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   172 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   173 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   174 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   175 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   176 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   177 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   178 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   179 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   180 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   181 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   182 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   183 Episode Steps:    14 Reward: -13.0000 \n",
      "Total Epi:   184 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   185 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   186 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   187 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   188 Episode Steps:    13 Reward: -12.0000 \n",
      "Total Epi:   189 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   190 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   191 Episode Steps:    20 Reward: -19.0000 \n",
      "Total Epi:   192 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   193 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   194 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   195 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   196 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   197 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   198 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   199 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   200 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   201 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   202 Episode Steps:    11 Reward: -10.0000 \n",
      "Total Epi:   203 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   204 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   205 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   206 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   207 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   208 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   209 Episode Steps:    16 Reward: -15.0000 \n",
      "Total Epi:   210 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   211 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   212 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   213 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   214 Episode Steps:    18 Reward: -17.0000 \n",
      "Total Epi:   215 Episode Steps:     9 Reward: -8.0000 \n",
      "Total Epi:   216 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   217 Episode Steps:     8 Reward: -7.0000 \n",
      "Total Epi:   218 Episode Steps:    12 Reward: -11.0000 \n",
      "Total Epi:   219 Episode Steps:    10 Reward: -9.0000 \n",
      "Total Epi:   220 Episode Steps:    11 Reward: -10.0000 \n"
     ]
    }
   ],
   "source": [
    "size = (5, 5)\n",
    "start_cell = (0, 0)\n",
    "obstacles = [(2, 1)]\n",
    "terminating_state = (4, 4)\n",
    "gamma = 0.9\n",
    "alpha = 0.1\n",
    "episodes = 220\n",
    "\n",
    "gw = GridWorld(size, start_cell, obstacles, terminating_state)\n",
    "solver = Sarsa(gw, gamma, alpha, episodes)\n",
    "\n",
    "while not solver.is_learning_finished():\n",
    "    solver.one_episode()\n",
    "    sum_rewards = solver.sum_rewards[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_rewards = solver.trajectory()\n",
    "print(sum_rewards)\n",
    "plot_learning_curve(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: 1 [-4.73636577 -4.73192671 -4.64510361 -4.65193457] right\n",
      "state: 2 [-4.27715998 -4.15878394 -4.12592096 -4.14289359] right\n",
      "state: 3 [-3.65742235 -3.58902775 -3.5979282  -3.60007558] up\n",
      "state: 4 [-3.05895217 -3.05098285 -3.05580474 -3.07214056] up\n",
      "state: 5 [-2.59205449 -2.62394794 -2.73622198 -2.58358291] down\n",
      "state: 6 [-4.22096787 -4.24668522 -4.15511044 -4.15798688] right\n",
      "state: 7 [-3.81062005 -3.80844511 -3.7350075  -3.82915659] right\n",
      "state: 8 [-3.15120305 -3.24767943 -3.16236928 -3.15566153] left\n",
      "state: 9 [-2.65754427 -2.57953292 -2.58659187 -2.5801632 ] up\n",
      "state: 10 [-2.12329561 -2.03392313 -1.98749161 -1.93154479] down\n",
      "state: 11 [-3.67719372 -3.69247202 -3.65289327 -3.64558681] down\n",
      "state: 12 [0. 0. 0. 0.] left\n",
      "state: 13 [-2.58372914 -2.63392419 -2.50104793 -2.50785683] right\n",
      "state: 14 [-1.93704491 -1.88555314 -1.86822276 -1.86155378] down\n",
      "state: 15 [-1.19987523 -1.37793007 -1.32071331 -1.02680571] down\n",
      "state: 16 [-3.07443054 -3.12202337 -3.06297952 -3.07688976] right\n",
      "state: 17 [-2.59412024 -2.45430066 -2.44743205 -2.4528541 ] right\n",
      "state: 18 [-1.84862069 -1.95156932 -1.83300547 -1.83907609] right\n",
      "state: 19 [-1.20629475 -1.14801168 -1.01794939 -1.02809159] right\n",
      "state: 20 [-0.56609499 -0.80615283 -0.4348873   0.        ] down\n",
      "state: 21 [-2.57111603 -2.6651333  -2.56633777 -2.61881563] right\n",
      "state: 22 [-1.93029625 -1.916421   -1.89970655 -2.08055991] right\n",
      "state: 23 [-1.35967798 -1.25652507 -1.00335941 -1.19315905] right\n",
      "state: 24 [-0.43911495 -0.52747615  0.         -0.40951   ] right\n",
      "state: 25 [0. 0. 0. 0.] left\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "name_action = [\"left\", \"up\", \"right\", \"down\"]\n",
    "for i in range (5):\n",
    "    for k in range (5):\n",
    "        action = name_action[np.argmax(solver.q_table[:,i,k])]\n",
    "        print(\"state:\", count, solver.q_table[:,i,k], action)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
